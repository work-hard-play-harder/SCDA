{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Sparse Convolutional Denoising Autoencoders for Genotype Imputation <span class=\"tocSkip\"></span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Dataset\" data-toc-modified-id=\"Dataset-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-data\" data-toc-modified-id=\"Loading-data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Loading data</a></span></li><li><span><a href=\"#Sample-visualization\" data-toc-modified-id=\"Sample-visualization-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Sample visualization</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Preprocessing</a></span></li></ul></li><li><span><a href=\"#Method\" data-toc-modified-id=\"Method-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Method</a></span><ul class=\"toc-item\"><li><span><a href=\"#Build-model\" data-toc-modified-id=\"Build-model-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Build model</a></span></li><li><span><a href=\"#Generate-data\" data-toc-modified-id=\"Generate-data-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Generate data</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Plot\" data-toc-modified-id=\"Plot-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Plot</a></span></li></ul></li><li><span><a href=\"#Prediction-on-test-data\" data-toc-modified-id=\"Prediction-on-test-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Prediction on test data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Genotype imputation, where missing genotypes can be computationally imputed, is an essential tool in genomic analysis ranging from genome wide associations to phenotype prediction. Traditional genotype imputation methods are typically based on Hidden Markov Models (HMMs) and are usually computationally expensive. Deep learning-based methods have been recently reported to nicely address the missing data problems in various fields. To explore the performance of deep learning for genotype imputation, in this study we propose a deep model called a Sparse Convolutional Denoising Autoencoder (SCDA) to impute missing genotypes. We constructed the SCDA model by using a convolutional layer that can extract various correlation or linkage patterns in the genotype data and applying a sparse weight matrix resulted from the L1 regularization to handle high dimensional data. We comprehensively evaluated the performance of the SCDA model in different scenarios for genotype imputation on the yeast and human genotype data respectively. Our results showed that SCDA has strong robustness and significantly outperforms three popular reference-free imputation methods including row average, k-nearest neighbors and singular-value decomposition. This study thus points to another novel application of deep learning models for missing data imputation in genomic studies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline   \n",
    "from matplotlib import pyplot as plt\n",
    "import pylab as pl\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Embedding, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, UpSampling1D, UpSampling2D, AveragePooling1D\n",
    "from keras.layers import Dropout, BatchNormalization, Activation\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.regularizers import l1, l1, l1_l2\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline   \n",
    "# from matplotlib import pyplot as plt\n",
    "# import pylab as pl\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.cm as cm\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.layers import Input, Embedding, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, UpSampling1D, UpSampling2D, AveragePooling1D\n",
    "# from tensorflow.keras.layers import Dropout, BatchNormalization, Activation\n",
    "# from tensorflow.keras.models import Model, Sequential\n",
    "# from tensorflow.keras.optimizers import RMSprop\n",
    "# from tensorflow.keras.regularizers import l1, l1, l1_l2\n",
    "# from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a seed for repeating the exact dataset splits\n",
    "# np.random.seed(seed=28213)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are {} samples, and each sample has {} SNPs. 4390 28220\n"
     ]
    }
   ],
   "source": [
    "input_name = 'data/genotype_full_1_2.txt'\n",
    "df_ori = pd.read_csv(input_name, sep='\\t', index_col=0)\n",
    "print('There are {} samples, and each sample has {} SNPs.'.format(df_ori.shape[0],df_ori.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>33070_chrI_33070_A_T</th>\n",
       "      <th>33147_chrI_33147_G_T</th>\n",
       "      <th>33152_chrI_33152_T_C</th>\n",
       "      <th>33200_chrI_33200_C_T</th>\n",
       "      <th>33293_chrI_33293_A_T</th>\n",
       "      <th>33328_chrI_33328_C_A</th>\n",
       "      <th>33348_chrI_33348_G_C</th>\n",
       "      <th>33403_chrI_33403_C_T</th>\n",
       "      <th>33502_chrI_33502_A_G</th>\n",
       "      <th>33548_chrI_33548_A_C</th>\n",
       "      <th>...</th>\n",
       "      <th>12048853_chrXVI_925593_G_C</th>\n",
       "      <th>12049199_chrXVI_925939_T_C</th>\n",
       "      <th>12049441_chrXVI_926181_C_T</th>\n",
       "      <th>12050613_chrXVI_927353_T_G</th>\n",
       "      <th>12051167_chrXVI_927907_A_C</th>\n",
       "      <th>12051240_chrXVI_927980_A_G</th>\n",
       "      <th>12051367_chrXVI_928107_C_T</th>\n",
       "      <th>12052782_chrXVI_929522_C_T</th>\n",
       "      <th>12052988_chrXVI_929728_A_G</th>\n",
       "      <th>12053130_chrXVI_929870_C_T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01_01</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_02</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_03</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_04</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01_06</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28220 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       33070_chrI_33070_A_T  33147_chrI_33147_G_T  33152_chrI_33152_T_C  \\\n",
       "SAMID                                                                     \n",
       "01_01                     1                     1                     1   \n",
       "01_02                     1                     1                     1   \n",
       "01_03                     2                     2                     2   \n",
       "01_04                     1                     1                     1   \n",
       "01_06                     2                     2                     2   \n",
       "\n",
       "       33200_chrI_33200_C_T  33293_chrI_33293_A_T  33328_chrI_33328_C_A  \\\n",
       "SAMID                                                                     \n",
       "01_01                     1                     1                     1   \n",
       "01_02                     1                     1                     1   \n",
       "01_03                     2                     2                     2   \n",
       "01_04                     1                     1                     1   \n",
       "01_06                     2                     2                     2   \n",
       "\n",
       "       33348_chrI_33348_G_C  33403_chrI_33403_C_T  33502_chrI_33502_A_G  \\\n",
       "SAMID                                                                     \n",
       "01_01                     1                     1                     1   \n",
       "01_02                     1                     1                     1   \n",
       "01_03                     2                     2                     2   \n",
       "01_04                     1                     1                     1   \n",
       "01_06                     2                     2                     2   \n",
       "\n",
       "       33548_chrI_33548_A_C  ...  12048853_chrXVI_925593_G_C  \\\n",
       "SAMID                        ...                               \n",
       "01_01                     1  ...                           2   \n",
       "01_02                     1  ...                           2   \n",
       "01_03                     2  ...                           1   \n",
       "01_04                     1  ...                           1   \n",
       "01_06                     2  ...                           2   \n",
       "\n",
       "       12049199_chrXVI_925939_T_C  12049441_chrXVI_926181_C_T  \\\n",
       "SAMID                                                           \n",
       "01_01                           2                           2   \n",
       "01_02                           2                           2   \n",
       "01_03                           1                           1   \n",
       "01_04                           1                           1   \n",
       "01_06                           2                           2   \n",
       "\n",
       "       12050613_chrXVI_927353_T_G  12051167_chrXVI_927907_A_C  \\\n",
       "SAMID                                                           \n",
       "01_01                           2                           2   \n",
       "01_02                           2                           2   \n",
       "01_03                           1                           1   \n",
       "01_04                           1                           1   \n",
       "01_06                           2                           2   \n",
       "\n",
       "       12051240_chrXVI_927980_A_G  12051367_chrXVI_928107_C_T  \\\n",
       "SAMID                                                           \n",
       "01_01                           2                           2   \n",
       "01_02                           2                           2   \n",
       "01_03                           1                           1   \n",
       "01_04                           1                           1   \n",
       "01_06                           2                           2   \n",
       "\n",
       "       12052782_chrXVI_929522_C_T  12052988_chrXVI_929728_A_G  \\\n",
       "SAMID                                                           \n",
       "01_01                           2                           2   \n",
       "01_02                           2                           2   \n",
       "01_03                           1                           1   \n",
       "01_04                           1                           1   \n",
       "01_06                           2                           2   \n",
       "\n",
       "       12053130_chrXVI_929870_C_T  \n",
       "SAMID                              \n",
       "01_01                           2  \n",
       "01_02                           2  \n",
       "01_03                           1  \n",
       "01_04                           1  \n",
       "01_06                           2  \n",
       "\n",
       "[5 rows x 28220 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # take a small part to test code\n",
    "# df_ori = df_ori.iloc[0:1000:, 0:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first sample in dataset\n",
    "vis_sample=df_ori.iloc[0].values[:28220].reshape(166,170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw first train sample, which was reshaped to (50,100)\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.gca()\n",
    "cmap = mpl.colors.ListedColormap([ 'blue', 'red'])\n",
    "im = ax.imshow(vis_sample, cmap=cmap)\n",
    "# create an axes on the right side of ax. The width of cax will be 5%\n",
    "# of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "# divider = make_axes_locatable(ax)\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.tick_params(labelsize=30)\n",
    "plt.rcParams[\"font.family\"] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "# plt.colorbar(im, cax=cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace -1 with 0\n",
    "df_ori[df_ori == 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4390, 28220, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode\n",
    "df_onehot = to_categorical(df_ori)\n",
    "df_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3512, 28220, 2), (878, 28220, 2))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split df to train and test\n",
    "train_X, test_X = train_test_split(df_onehot, test_size=0.2)\n",
    "\n",
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2809, 28220, 2), (703, 28220, 2))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split df to train and valid\n",
    "train_X, valid_X = train_test_split(train_X, test_size=0.2)\n",
    "\n",
    "train_X.shape, valid_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "missing_perc = 0\n",
    "\n",
    "# training\n",
    "batch_size = 32\n",
    "lr = 1e-3\n",
    "epochs = 20\n",
    "\n",
    "# conv1D\n",
    "feature_size = train_X.shape[1]\n",
    "inChannel = train_X.shape[2]\n",
    "kr = 1e-5\n",
    "drop_prec = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCDA = Sequential()\n",
    "# encoder\n",
    "SCDA.add(Conv1D(32, 5, padding='same',activation='relu',kernel_regularizer=l1(kr),input_shape=(feature_size, inChannel)))\n",
    "SCDA.add(MaxPooling1D(pool_size=2))\n",
    "SCDA.add(Dropout(drop_prec))\n",
    "          \n",
    "SCDA.add(Conv1D(64, 5, padding='same', activation='relu', kernel_regularizer=l1(kr))) \n",
    "SCDA.add(MaxPooling1D(pool_size=2)) \n",
    "SCDA.add(Dropout(drop_prec))\n",
    "\n",
    "# bridge\n",
    "SCDA.add(Conv1D(128, 5, padding='same', activation='relu', kernel_regularizer=l1(kr)))\n",
    "\n",
    "# decoder\n",
    "SCDA.add(Conv1D(64, 5, padding='same', activation='relu', kernel_regularizer=l1(kr))) \n",
    "SCDA.add(UpSampling1D(2)) \n",
    "SCDA.add(Dropout(drop_prec))\n",
    "          \n",
    "SCDA.add(Conv1D(32, 5, padding='same', activation='relu', kernel_regularizer=l1(kr))) \n",
    "SCDA.add(UpSampling1D(2))\n",
    "SCDA.add(Dropout(drop_prec))\n",
    "\n",
    "SCDA.add(Conv1D(inChannel, 5, activation='sigmoid', padding='same',kernel_regularizer=l1(kr))) \n",
    "\n",
    "\n",
    "# compile\n",
    "SCDA.compile(loss='categorical_crossentropy', \n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "SCDA.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates data for denoising autoencoder.\n",
    "class DataGenerator(keras.utils.Sequence):    \n",
    "    def __init__(self, batch_size, x_dataset, missing_perc=0.1, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.x = x_dataset\n",
    "        self.missing_perc=missing_perc\n",
    "        self.shuffle = shuffle\n",
    "        # triggered once at the very beginning as well as at the end of each epoch.\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denote the number of batches per epoch\n",
    "        return int(np.floor(self.x.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generates one batch of data\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) *\n",
    "                               self.batch_size]\n",
    "        self.x_missing = self.x[indexes].copy()\n",
    "\n",
    "        # Generates missing genotypes\n",
    "        # different missing loci for each individuals\n",
    "        for i in range(self.x_missing.shape[0]):\n",
    "            missing_size= int(self.missing_perc*self.x_missing.shape[1])\n",
    "            missing_index = np.random.randint(self.x_missing.shape[1], size=missing_size)\n",
    "            self.x_missing[i, missing_index, :] = 0\n",
    "\n",
    "        return self.x_missing, self.x[indexes]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Update indexes after each epoch\n",
    "        self.indexes = np.arange(self.x.shape[0])\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(\n",
    "    batch_size=batch_size, x_dataset=train_X, missing_perc=missing_perc)\n",
    "valid_generator = DataGenerator(\n",
    "    batch_size=batch_size, x_dataset=valid_X, missing_perc=missing_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator.__getitem__(17)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping call back with val_loss monitor\n",
    "EarlyStopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "# model checkpoint call back with val_acc monitor\n",
    "ModelCheckpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'models/SCDA_checkpoint.{epoch:02d}-{val_acc:.4f}.h5',\n",
    "    monitor='val_acc',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/87 [=======>......................] - ETA: 6:36 - loss: nan - acc: 0.9152"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1ca3431cc71b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SCDA_train = SCDA.fit_generator(\n",
    "    generator=train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=[EarlyStopping, ModelCheckpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss curve on validation data\n",
    "loss = SCDA_train.history['loss']\n",
    "val_loss = SCDA_train.history['val_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(len(loss)), loss, 'bo', label='Training loss')\n",
    "plt.plot(range(len(val_loss)), val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy curve on validation data\n",
    "acc = SCDA_train.history['acc']\n",
    "val_acc = SCDA_train.history['val_acc']\n",
    "plt.figure()\n",
    "plt.plot(range(len(acc)), acc, 'bo', label='Training acc')\n",
    "plt.plot(range(len(val_acc)), val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_missing = test_X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=[]\n",
    "for i in range(test_X_missing.shape[0]):\n",
    "    # Generates missing genotypes\n",
    "    missing_size= int(missing_perc*test_X_missing.shape[1])\n",
    "    missing_index = np.random.randint(test_X_missing.shape[1], size=missing_size)\n",
    "    test_X_missing[i, missing_index, :] = 0\n",
    "    \n",
    "    # predict\n",
    "    predict_onehot = SCDA.predict(test_X_missing)\n",
    "    # only care the missing position\n",
    "    predict_missing_onehot = predict_onehot[:, missing_index, :]\n",
    "    predict_missing=np.argmax(predict_missing_onehot, axis=2)\n",
    "    \n",
    "    # label\n",
    "    label_missing_onehot = test_X[:, missing_index, :]\n",
    "    label_missing=np.argmax(label_missing_onehot, axis=2)\n",
    "\n",
    "    # accuracy\n",
    "    correct_prediction = np.equal(predict_missing, label_missing)\n",
    "    accuracy.append(np.mean(correct_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_acc=np.mean(accuracy)\n",
    "print('The average accuracy on test data is {}'.format(avg_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
